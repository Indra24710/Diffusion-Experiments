dataset:
  path: "D:\\AI projects\\Diffusion-Experiments\\data\\datafiles\\celebahq"
  num_workers: 4
  filetype: "jpg"
  dataset_type: "vanilla"
model:
  name: "ldm-celebahq-256"
  type: "unconditional"
  root: "CompVis/ldm-celebahq-256"
  unet: "unet"
  vqvae: "vqvae"
  scheduler:
    "beta_end": 0.0195
    "beta_schedule": "scaled_linear"
    "beta_start": 0.0015
    "clip_sample": false
    "trained_betas": null
  inverse_scheduler: "inverse_scheduler"
  generation:
    num_inference_steps: 50
  inversion:
    num_inference_steps: 50
    optimization_steps: 100
    lr: 1e-3
    loss_threshold: 0.003
    losses:
      - name: 'L1 Image loss'
        use: False
        weight: 1
      - name: 'L2 Image loss'
        use: False
        weight: 1
      - name: 'L1 Perceptual loss'
        use: False
        weight: 1
      - name: 'L2 Perceptual loss'
        use: True
        weight: 1
      - name: 'Population K2 Normality Loss'
        use: True
        weight: 1
    optimizer:
      name: "adam"
      params:
        betas: [0.9, 0.999]
        lr: 0.001
experiment:
  expt_type: "hybrid_ddim_inversion" # ddim_inversion, hybrid_ddim_inversion, optimization_inversion
  log_root_dir: "logs"
  seed: 1000
  use_tensorboard: true
  batch_size: 1
  shuffle_dataset: true
  num_files: 100
